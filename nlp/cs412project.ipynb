{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs412project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "dYGZgACMLIzv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Opening and Reading the files into a list \n",
        "with open(\"imdb_labelled.txt\",\"r\") as text_file:\n",
        "    lines = text_file.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hgm-GNg5LLku",
        "colab_type": "code",
        "outputId": "46f8f7a1-1c0e-4e74-db21-4cd7a2a1bf4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "cell_type": "code",
      "source": [
        "# split the line by new-line character such that each line has one element of the list\n",
        "lines[0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A very, very, very slow-moving, aimless movie about a distressed, drifting young man.  \\t0',\n",
              " 'Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.  \\t0',\n",
              " 'Attempting artiness with black & white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.  \\t0',\n",
              " 'Very little music or anything to speak of.  \\t0',\n",
              " 'The best scene in the movie was when Gerardo is trying to find a song that keeps running through his head.  \\t1',\n",
              " \"The rest of the movie lacks art, charm, meaning... If it's about emptiness, it works I guess because it's empty.  \\t0\",\n",
              " 'Wasted two hours.  \\t0',\n",
              " 'Saw the movie today and thought it was a good effort, good messages for kids.  \\t1',\n",
              " 'A bit predictable.  \\t0',\n",
              " 'Loved the casting of Jimmy Buffet as the science teacher.  \\t1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "XSPU0UGgLNbe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Read the lines from both the files and append in same list\n",
        "with open(\"yelp_labelled.txt\",\"r\") as text_file:\n",
        "    lines += text_file.read().split('\\n')\n",
        "with open(\"amazon_cells_labelled.txt\",\"r\") as text_file:\n",
        "    lines += text_file.read().split('\\n')\n",
        "# print(lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sHDXTPqALQNO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split by tab and remove corrupted data if any or lines which are not tab seperated\n",
        "lines = [line.split(\"\\t\") for line in lines if len(line.split(\"\\t\"))==2 and line.split(\"\\t\")[1]!='']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XrFtNWq5LST-",
        "colab_type": "code",
        "outputId": "155ab383-d4d9-4802-9f4c-99354915935a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "# print the lines one is string and another is integer 0 or 1\n",
        "lines[0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['A very, very, very slow-moving, aimless movie about a distressed, drifting young man.  ',\n",
              "  '0'],\n",
              " ['Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.  ',\n",
              "  '0'],\n",
              " ['Attempting artiness with black & white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.  ',\n",
              "  '0'],\n",
              " ['Very little music or anything to speak of.  ', '0'],\n",
              " ['The best scene in the movie was when Gerardo is trying to find a song that keeps running through his head.  ',\n",
              "  '1'],\n",
              " [\"The rest of the movie lacks art, charm, meaning... If it's about emptiness, it works I guess because it's empty.  \",\n",
              "  '0'],\n",
              " ['Wasted two hours.  ', '0'],\n",
              " ['Saw the movie today and thought it was a good effort, good messages for kids.  ',\n",
              "  '1'],\n",
              " ['A bit predictable.  ', '0'],\n",
              " ['Loved the casting of Jimmy Buffet as the science teacher.  ', '1']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "7Cp2LafdLUBp",
        "colab_type": "code",
        "outputId": "4e25be87-5aab-4a1f-8f43-5fea0375a9eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "cell_type": "code",
      "source": [
        "# Seperate the sentences\n",
        "train_documents = [line[0] for line in lines]\n",
        "train_documents[0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A very, very, very slow-moving, aimless movie about a distressed, drifting young man.  ',\n",
              " 'Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.  ',\n",
              " 'Attempting artiness with black & white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.  ',\n",
              " 'Very little music or anything to speak of.  ',\n",
              " 'The best scene in the movie was when Gerardo is trying to find a song that keeps running through his head.  ',\n",
              " \"The rest of the movie lacks art, charm, meaning... If it's about emptiness, it works I guess because it's empty.  \",\n",
              " 'Wasted two hours.  ',\n",
              " 'Saw the movie today and thought it was a good effort, good messages for kids.  ',\n",
              " 'A bit predictable.  ',\n",
              " 'Loved the casting of Jimmy Buffet as the science teacher.  ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "4jL0M-ZaLVCJ",
        "colab_type": "code",
        "outputId": "77e273e6-8794-4dd6-983d-5f0d9a290214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Seperate the labels\n",
        "train_labels = [int(line[1]) for line in lines]\n",
        "train_labels[0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 1, 0, 0, 1, 0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "5r8To0LLLYkJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DuOZeIn1LZWR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Instatiate the Countvectorizer\n",
        "count_vectorizer = CountVectorizer(binary='true')\n",
        "# Train the documents\n",
        "train_documents_count = count_vectorizer.fit_transform(train_documents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T-XJBrs5_L1f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Instatiate the TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(binary='true')\n",
        "# Train the documents\n",
        "train_documents_tfidf = tfidf_vectorizer.fit_transform(train_documents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AiIkELExLajJ",
        "colab_type": "code",
        "outputId": "375c0dfa-14fa-4a20-f400-6223e6b0fbb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "# print(train_documents)\n",
        "\n",
        "# print first document\n",
        "print(train_documents_count[0])\n",
        "print(train_documents_tfidf[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 2764)\t1\n",
            "  (0, 5139)\t1\n",
            "  (0, 1401)\t1\n",
            "  (0, 1331)\t1\n",
            "  (0, 75)\t1\n",
            "  (0, 2954)\t1\n",
            "  (0, 166)\t1\n",
            "  (0, 2956)\t1\n",
            "  (0, 4133)\t1\n",
            "  (0, 4890)\t1\n",
            "  (0, 4890)\t0.1705983714180228\n",
            "  (0, 4133)\t0.2866535155030133\n",
            "  (0, 2956)\t0.344069060569113\n",
            "  (0, 166)\t0.39646013048660145\n",
            "  (0, 2954)\t0.18376294855720401\n",
            "  (0, 75)\t0.21995093564903362\n",
            "  (0, 1331)\t0.39646013048660145\n",
            "  (0, 1401)\t0.39646013048660145\n",
            "  (0, 5139)\t0.3527636851677853\n",
            "  (0, 2764)\t0.303662775383371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SOQv4n6VLb6y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training Phase\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "count_classifier = BernoulliNB().fit(train_documents_count, train_labels)\n",
        "tfidf_classifier = BernoulliNB().fit(train_documents_tfidf, train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CapoSvdlLfjL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test Phase\n",
        "# Opening and Reading the test file into a list \n",
        "import xlrd\n",
        "\n",
        "workbook = xlrd.open_workbook(\"yelp-test.xlsx\")\n",
        "sheet = workbook.sheet_by_index(1)  #iki sheet var. Bizimki ikincisi olduÄŸundan index 1\n",
        "\n",
        "test_documents = list()\n",
        "for row in range(sheet.nrows):\n",
        "\ttest_documents.append(sheet.cell(row,0).value)\n",
        "\t#print(sheet.cell(row, 0).value)\n",
        "\n",
        "test_labels = list()\n",
        "for row in range(sheet.nrows):\n",
        "\ttest_labels.append(sheet.cell(row,1).value)\n",
        "\t#print(sheet.cell(row, 1).value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iLCBHJMXK8mb",
        "colab_type": "code",
        "outputId": "bb8c19b0-774a-4cea-97a3-07e7eb8d75a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "# Making the predictions\n",
        "pred_count = count_classifier.predict(count_vectorizer.transform(test_documents))\n",
        "pred_tfidf = tfidf_classifier.predict(tfidf_vectorizer.transform(test_documents))\n",
        "\n",
        "# Print the accuracy scores\n",
        "print(\"Count Vectorizer Accuracy Score: \", count_classifier.score((count_vectorizer.transform(test_documents)), test_labels))\n",
        "print(\"Tf-Idf Vectorizer Accuracy Score: \", tfidf_classifier.score((tfidf_vectorizer.transform(test_documents)), test_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count Vectorizer Accuracy Score:  0.5643564356435643\n",
            "Tf-Idf Vectorizer Accuracy Score:  0.5643564356435643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sScbBbXrVG8E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_labels = numpy.asarray(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OCPdgtbTM2qB",
        "colab_type": "code",
        "outputId": "7046681d-e676-414a-8fdd-c5a54a506f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "# Create the confusion matrix and classification report\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(confusion_matrix(test_labels, pred_count))\n",
        "print('\\n')\n",
        "print(classification_report(test_labels, pred_count))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[35 30]\n",
            " [14 22]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.54      0.61        65\n",
            "           1       0.42      0.61      0.50        36\n",
            "\n",
            "   micro avg       0.56      0.56      0.56       101\n",
            "   macro avg       0.57      0.57      0.56       101\n",
            "weighted avg       0.61      0.56      0.57       101\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0hmYr6t__1WF",
        "colab_type": "code",
        "outputId": "a9dcdf32-f52e-4cf9-9c52-6a83053b06f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "# Create the confusion matrix and classification report\n",
        "print(confusion_matrix(test_labels, pred_tfidf))\n",
        "print('\\n')\n",
        "print(classification_report(test_labels, pred_tfidf))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[35 30]\n",
            " [14 22]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.54      0.61        65\n",
            "           1       0.42      0.61      0.50        36\n",
            "\n",
            "   micro avg       0.56      0.56      0.56       101\n",
            "   macro avg       0.57      0.57      0.56       101\n",
            "weighted avg       0.61      0.56      0.57       101\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mp8EmjDiA9VT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "For this problem, we have used the Count Vectorizer and TF-IDF Vectorizer algorithms to learn the vocabulary. They have produced the same results. Then, we attempted to use k-fold cross-validation with our training data. The generated models provided no improvement, thus we have omitted them from the notebook for clarity. The results can be seen above."
      ]
    }
  ]
}